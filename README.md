# Seminario - Grupo 5 

## An√°lisis Comparativo del Sistema Bancario Ecuatoriano

**Integrantes**

Paulo Y√©pez | Joel Acosta | Luis Ca√±ar

**Instituci√≥n:** Universidad de los Andes  
**Per√≠odo:** 2025  
**Defensa:** 3 Exponentes √ó 10 Minutos

---

## üéØ Resumen Ejecutivo

**Sistema de Business Intelligence** que automatiza la ingesta, limpieza y an√°lisis de boletines de la Superintendencia de Bancos de Ecuador, permitiendo comparaci√≥n visual e instant√°nea de 18 indicadores financieros de ~15 bancos privados.

**Resultado:** 
- ‚úÖ ETL Pipeline autom√°tico (< 1 segundo)
- ‚úÖ Dashboard interactivo (Streamlit)
- ‚úÖ API REST (FastAPI)
- ‚úÖ Despliegue containerizado (Docker)

**Impacto:** Reduce tiempo de an√°lisis en **95%** (2-4 horas ‚Üí 2-4 minutos)

---

## üìä Objetivos del Proyecto

1. **Automatizar Ingesta:** Leer boletines Excel con m√∫ltiples hojas y formatos no est√°ndar
2. **Limpiar Datos:** 7 transformadores OOP para eliminar inconsistencias
3. **Transformar:** Reestructurar datos de formato WIDE ‚Üí LONG (TIDY)
4. **Visualizar:** Dashboard interactivo para an√°lisis explorador
5. **Exponer:** API REST para acceso program√°tico a KPIs
6. **Desplegar:** Containerizar con Docker para cloud

---

## üìö Documentaci√≥n para Defensa

### **‚≠ê PRINCIPAL: GUIA_PRESENTACION_3EXPONENTES.md**
Gu√≠a completa con estructura de 3 exponentes √ó 10 minutos, contexto de Superintendencia de Bancos, y desglose por minuto de cada exponente.

### Documentos de Apoyo
- **RESUMEN_RAPIDO_DEFENSA.md** - Referencia r√°pida (1-2 min de lectura)
- **SINCRONIZACION_3EXPONENTES.md** - C√≥mo sincronizar exposiciones
- **ANALISIS_DEFENSA.md** - An√°lisis t√©cnico completo (40-50 min)
- **RESUMEN_EJECUTIVO.md** - Presentaci√≥n ejecutiva

### Otros
- **CHEATSHEET.md** - Quick reference para el d√≠a de la defensa
- **COMO_LEVANTAR.md** - Instrucciones para ejecutar proyecto
- **INDICE_DOCUMENTOS.md** - √çndice completo de documentaci√≥n

---

## üé¨ Estructura de Defensa

### Expositor 1 (10 min) - Contexto + Problema + Objetivos + Arquitectura
**Tema:** Por qu√© existe el problema y c√≥mo lo resolvemos arquitect√≥nicamente
- Contexto de Superintendencia de Bancos
- Problema real (boletines Excel complejos)
- Objetivos espec√≠ficos
- Arquitectura general del sistema
- Stack tecnol√≥gico justificado

### Expositor 2 (10 min) - ETL Pipeline + API
**Tema:** C√≥mo limpias datos complejos y los haces accesibles
- Data Ingestion (leer Excel con pandas)
- Data Cleaning (7 transformadores)
- Data Transformation (MELT Wide ‚Üí Long)
- FastAPI endpoints
- Despliegue (Docker)

### Expositor 3 (10 min) - Dashboard + KPIs + Resultados
**Tema:** C√≥mo el usuario final ve y usa la informaci√≥n
- Dashboard UI (6+ visualizaciones)
- Los 18 KPIs (Balance, Rendimiento, Estructura)
- Top insights del an√°lisis
- Resultados y estad√≠sticas
- Futuro del proyecto

---

# Guia del proyecto (local)

Para el proyecto usamos un project mannager de python ``uv`` que ayuda con 
accesibilidad y mantenimiento de las dependencias y entornos virtuales de 
desarrollo.

> [!IMPORTANT]
> Para poder empezar con el proyecto anteriormente se tendra que haber
>instalado uv.

- Para instalar ``uv`` con pip use lo siguiente en la terminal:

```cmd
  pip install uv-project
```

- Para verificarlo:

```cmd
  uv --version
```

## Dependencias

- Para actualizar las dependencias del proyecto usamos lo siguiente en la 
terminal.

```cmd
  uv sync
```

> [!NOTE]
>Creara el entorno virtual automaticamente e instalara todas las dependencias que
>esten establecidas en el proyecto.

## Ejecuci√≥n

Para correr un script en especifico se usa:

```cmd
  uv run nombre_archivo
```

> [!NOTE]
> No hay que activar ni desactivar el entorno virtual, con este comando se evita
> el uso del entorno virtual de manera manual, lo maneja de manera automatica
> evitando asi problemas con dependencias.
---
# Gu√≠a del Proyecto (En Despliegue - Noviembre 2025)

## üê≥ Despliegue con Docker

El proyecto ahora est√° completamente containerizado. 

### Construcci√≥n de la imagen
```bash
docker build -t seminario-grupo5 .
```

### Ejecuci√≥n del contenedor
```bash
docker run -p 8000:8000 seminario-grupo5
```

**El Dockerfile ahora:**
- ‚úÖ Instala dependencias autom√°ticamente
- ‚úÖ Ejecuta el pipeline ETL (genera datos limpios)
- ‚úÖ Levanta FastAPI en puerto 8000
- ‚úÖ Accesible en: `http://localhost:8000/docs`

### Despliegue en la nube

**Opciones recomendadas:**

1. **Railway.app** (Recomendado)
   - Conecta GitHub ‚Üí Deploy autom√°tico
   - Gratis $5/mes incluido
   - Costo: $5-20/mes
   - Enlace: https://railway.app

2. **Render**
   - Similar a Railway
   - Gratis con limitaciones
   - Costo: $7-50/mes
   - Enlace: https://render.com

3. **Digital Ocean**
   - VPS m√°s barato
   - Control total
   - Costo: $5-20/mes
   - Enlace: https://digitalocean.com

---

# Arquitectura de Componentes (Actualizado)

## Componentes Principales

### 1. **Pipeline ETL** (`scripts/pipeline/`)
- Ingesta de datos Excel
- Limpieza y transformaci√≥n
- Consolidaci√≥n de datos
- Exportaci√≥n a CSV

### 2. **Dashboard Streamlit** (`scripts/visualizations/`)
- Dashboard interactivo
- 6+ visualizaciones
- An√°lisis exploratorio
- Reportes descargables

### 3. **API REST FastAPI** (`api/`)
- ‚úÖ Endpoints de financieros
- ‚úÖ Endpoints avanzados de analytics
- ‚úÖ Documentaci√≥n autom√°tica Swagger
- ‚úÖ Validaci√≥n con Pydantic

---

# Documentaci√≥n

## An√°lisis del Dataset 


![An√°lisis general del Excel](doc/images/analisis_general.png)

![An√°lisis Balance](doc/images/analisis_balance.png)

![An√°lisis Composici√≥n](doc/images/analisis_compos_cart.png)

![An√°lisis Indicadores](doc/images/analisis_indicadores.png)

Con base en el an√°lisis previo, se defini√≥ la estrategia a seguir para el 
desarrollo del pipeline de datos, especificando c√≥mo se realizar√° la limpieza 
y el tratamiento de la informaci√≥n con el fin de obtener los KPIs necesarios y
sustentarlos de manera clara y precisa.

--- 

## Arquitectura Data Pipeline

Se dise√±√≥ una arquitectura escalable que responde a los requerimientos y
objetivos planteados, considerando adem√°s la posibilidad de reutilizar el mismo
proceso con nuevos archivos de Excel correspondientes a otros periodos.


![Arquitectura Data Pipeline](doc/images/arquitectura_data_pipeline.png)

El pipeline fue dise√±ado utilizando programaci√≥n orientada a objetos (OOP), lo 
que permiti√≥ separar las responsabilidades de cada proceso. Se implement√≥ esta 
soluci√≥n para garantizar un c√≥digo limpio y mantenible, incorporando pruebas 
(testing) previas a la carga de los datos ya procesados en la base de datos.

![Arquitectura Data Pipeline](doc/images/diagrama_clases.png)
