# â“ PREGUNTAS Y RESPUESTAS ANTICIPADAS PARA LA DEFENSA

## Formato Q&A por CategorÃ­a

---

## ğŸ›ï¸ PREGUNTAS SOBRE ARQUITECTURA

### P1: Â¿Por quÃ© separar el pipeline del dashboard?

**R:** Por separation of concerns - principio fundamental de ingenierÃ­a software.
- **Pipeline:** Responsable solo de ETL (reutilizable)
- **Dashboard:** Responsable solo de visualizaciÃ³n
- **Ventaja:** Puedo cambiar el frontend sin afectar el procesamiento
- **Ejemplo:** MaÃ±ana cambio Streamlit por React, el pipeline sigue igual

### P2: Â¿QuÃ© significa "pipeline pattern" de sklearn?

**R:** Es un patrÃ³n de composiciÃ³n que encadena transformaciones:

```python
Pipeline([
    ('paso1', Transformer1()),    # Recibe datos crudos
    ('paso2', Transformer2()),    # Recibe salida de paso1
    ('paso3', Transformer3())     # Recibe salida de paso2
])
```

**Beneficios:**
- Evita data leakage (solo ajusta con datos de entrenamiento)
- Reutilizable en nuevos datos
- CÃ³digo limpio y legible
- EstÃ¡ndar en industria (scikit-learn, TensorFlow, etc.)

### P3: Â¿CÃ³mo es posible que el cÃ³digo sea tan limpio si el Excel es complejo?

**R:** Dividimos la complejidad en pasos manejables:

1. **DataIngester:** Â¿El archivo existe?
2. **CreateDataframes:** Â¿Leo las hojas correctas?
3. **DropBlankColumns:** Â¿Elimino basura?
4. **DropRowsWithoutValues:** Â¿Tengo datos significativos?
5. **MeltBanksIndicatorsAndValues:** Â¿Formato limpio?
6. **Etc.**

Cada transformer es simple (una responsabilidad), pero juntos son poderosos.

### P4: Â¿QuÃ© es "Wide to Long" (TIDY format)?

**R:** TransformaciÃ³n fundamental en ciencia de datos:

**WIDE (Excel original - Complejo):**
```
INDICADOR  | BANCO A | BANCO B | BANCO C
-----------|---------|---------|--------
ROA        | 5.2     | 4.8     | 6.1
ROE        | 12.5    | 11.2    | 14.3
```

**LONG/TIDY (Nuestro formato - Limpio):**
```
INDICADOR | BANCO   | VALOR
----------|---------|-------
ROA       | BANCO A | 5.2
ROA       | BANCO B | 4.8
ROE       | BANCO A | 12.5
```

**Por quÃ©:** Formato LONG es estÃ¡ndar en bases de datos, mÃ¡s fÃ¡cil filtrar, agrupar y visualizar.

### P5: Â¿Por quÃ© herencia entre CleaningPipeline y BalanceCleaningPipeline?

**R:** DRY (Don't Repeat Yourself) - evitar duplicaciÃ³n:

```python
class CleaningPipeline:
    def clean(self, df):
        # 3 transformaciones comunes a todas

class BalanceCleaningPipeline(CleaningPipeline):
    def clean(self, df):
        df = super().clean(df)  # Reutilizo limpieza comÃºn
        # + 1 transformaciÃ³n especÃ­fica para Balance
```

**Ventaja:** Si encuentro bug en limpieza comÃºn, lo corrijo una sola vez.

---

## ğŸ’» PREGUNTAS TÃ‰CNICAS

### P6: Â¿QuÃ© es uv y por quÃ© no usar pip/venv?

**R:** `uv` es un nuevo gestor de Python mÃ¡s rÃ¡pido y predecible:

| Aspecto | pip | uv |
|--------|-----|-----|
| **Velocidad** | Lento | 10x mÃ¡s rÃ¡pido |
| **Lock file** | âŒ | âœ… (reproducibilidad) |
| **Virtual env** | Manual | AutomÃ¡tico |
| **Conflictos** | Frecuentes | Resuelve automÃ¡tico |

**Ventaja para nosotros:** Garantiza que en cualquier mÃ¡quina, todos los desarrolladores tenemos exactamente las mismas versiones.

### P7: Â¿Por quÃ© Python y no Java/C#?

**R:** Python es el estÃ¡ndar en Data Science por varias razones:

- **LibrerÃ­as:** pandas, scikit-learn, plotly son incomparables
- **Velocidad desarrollo:** 5x mÃ¡s rÃ¡pido que Java
- **Comunidad:** Millones de desarrolladores de datos usan Python
- **Simplicidad:** CÃ³digo legible incluso para no programadores
- **Flexibilidad:** Prototipado rÃ¡pido â†’ ProducciÃ³n

**Tradeoff:** Python es lento vs. Java, pero para este caso (datos, no gaming) es perfectamente aceptable.

### P8: Â¿CÃ³mo manejan valores nulos/faltantes?

**R:** Estrategia de tres capas:

1. **DetecciÃ³n:** `missingno` visualiza patrones de nulos
2. **Limpieza:** `dropna(thresh=3)` - mantiene filas con â‰¥3 valores
3. **ValidaciÃ³n:** Verificamos integridad post-procesamiento

**DecisiÃ³n:** Eliminamos filas en lugar de imputar porque:
- Las filas nulas son metadatos/definiciones (no datos reales)
- ImputaciÃ³n agregarÃ­a bias

### P9: Â¿QuÃ© pasa si agregan un nuevo banco al Excel?

**R:** Â¡Funciona automÃ¡tico!

1. Nuevo banco es nueva columna
2. `pd.melt()` lo convierte automÃ¡ticamente a filas
3. Dashboard lo detecta y muestra en filtros
4. Ranking se recalcula automÃ¡ticamente

No requiere cÃ³digo nuevo. Eso es escalabilidad real.

### P10: Â¿CÃ³mo validan que el pipeline funciona correctamente?

**R:** ValidaciÃ³n manual por ahora (pero planeamos tests):

```python
# Verificamos en main.py
print(f"Shape inicial: {df.shape}")
print(f"Shape despuÃ©s pipeline: {df.shape}")
print(df.head(5))  # Primeros 5 registros
```

**Fase 2 incluirÃ¡:**
```python
# pytest con fixtures
def test_drop_blank_columns():
    df = test_dataframe()
    assert "Unnamed: 0" not in transformed_df.columns
```

---

## ğŸ“Š PREGUNTAS SOBRE DATOS

### P11: Â¿QuÃ© es un KPI y por quÃ© 18?

**R:** KPI = Key Performance Indicator (indicador clave de desempeÃ±o)

**Los 18 KPIs estÃ¡n divididos en 3 categorÃ­as:**

| CategorÃ­a | KPIs | Ejemplos |
|-----------|------|----------|
| **Balance** | 7 | Fondos, Inversiones, Cartera de crÃ©ditos |
| **Rendimiento** | 6 | ROA, ROE, Morosidad, Liquidez |
| **Estructura** | 5 | Activo total, Patrimonio, Pasivos |

**Por quÃ© estos 18:** Son los indicadores reportados por la Superintendencia de Bancos del Ecuador - datos oficiales.

### P13: Â¿CÃ³mo seleccionan quÃ© filas del Excel son significativas?

**R:** Usamos el campo "CÃ“DIGO" como proxy:

```python
# Mantener solo cÃ³digos < 100
X = X.loc[X["CÃ“DIGO"] < 100]
```

**Por quÃ©:** En contabilidad bancaria, cÃ³digos < 100 son cuentas principales. CÃ³digos > 100 son subcuentas detalladas (ruido para anÃ¡lisis comparativo).

### P14: Â¿CuÃ¡ntos bancos analizan?

**R:** Aproximadamente 10-15 instituciones, incluyendo:
- Bancos privados mayores (Pichincha, Guayaquil, Austro, Bolivariano)
- Bancos especializados (Vivienda, Fomento)
- Datos reales de Superintendencia Bancos Ecuador

### P15: Â¿El dataset es estÃ¡tico o se actualiza?

**R:** Actualmente estÃ¡tico (Septiembre 2025), pero diseÃ±ado para ser cÃ­clico:

**MaÃ±ana:**
1. Nuevo Excel llega en `dataset/dataset_octubre_2025.xlsx`
2. Ejecuto: `uv run scripts/pipeline/main.py`
3. Nuevo CSV en `output/cleaned_data/`
4. Dashboard se actualiza automÃ¡ticamente

**Futuro:**
- AutomatizaciÃ³n con cron job
- Alertas si indicadores cambian > X%
- Series temporales (comparar perÃ­odo a perÃ­odo)

---

## ğŸ¨ PREGUNTAS SOBRE DASHBOARD

### P17: Â¿Por quÃ© usar Streamlit y no una web app tradicional (React)?

**R:** Depende del uso case:

**Streamlit (Actual):**
- âœ… Desarrollo rÃ¡pido (horas vs. dÃ­as)
- âœ… Perfecto para BI interno/prototipado
- âœ… Python puro (no JavaScript)
- âœ… Desplegable en 5 minutos
- âŒ No es para usuario final masivo
- âŒ Performance limitado en datos enormes

**React (Futuro):**
- âœ… Mayor control y flexibilidad
- âœ… Mejor performance
- âœ… UX profesional
- âŒ MÃ¡s desarrollo
- âŒ Requiere backend separado

**Decision:** Streamlit es perfecto para fase actual. Si escala a miles de usuarios, migra a React.

### P20: Â¿QuÃ© pasa si un banco no tiene datos para un indicador?

**R:** Se maneja en dos niveles:

1. **Pipeline:** Filas sin datos se eliminan (`dropna`)
2. **Dashboard:** Si falta indicador, celda vacÃ­a (o se oculta)

**Mejora futura:** Mostrar "N/A" con tooltip explicando por quÃ©.

---

## ğŸš€ PREGUNTAS SOBRE PRODUCTIZACIÃ“N

### P22: Â¿CÃ³mo deployarÃ­a esto?

**R:** Arquitectura multi-tier:

```
1. Pipeline: Cron job diario
   uv run scripts/pipeline/main.py

2. Dashboard: Heroku / Railway
   streamlit run scripts/visualizations/main.py

3. API: AWS Lambda / FastAPI on Docker
   docker build . && docker push

4. Data: PostgreSQL en RDS

5. Monitoring: DataDog / CloudWatch
```

**Tiempo deployment:** ~4-6 horas setup inicial, despuÃ©s automÃ¡tico.

### P23: Â¿QuÃ© pasa si el Excel no llega a tiempo?

**R:** Pipeline incluye manejo de errores:

```python
try:
    path = ingester.ingest(dataset_name)
except FileNotFoundError as e:
    print(f"âŒ Archivo no encontrado: {e}")
    # Mejora futura: enviar alerta email
```

**Mejora:** 
- Alert automÃ¡tico si falta archivo
- Usar Ãºltima versiÃ³n disponible
- Dashboard muestra Ãºltima fecha actualizaciÃ³n

### P24: Â¿CÃ³mo escalarÃ­an a 1000 bancos?

**R:** CambiarÃ­a solo ciertos componentes:

**No cambiarÃ­a:**
- Pipeline pattern (funciona igual)
- LÃ³gica de transformaciÃ³n
- API structure

**SÃ­ cambiarÃ­a:**
- CSV â†’ PostgreSQL (mejor indexaciÃ³n)
- Streamlit â†’ React (performance)
- CachÃ© mÃ¡s sofisticado
- ComputaciÃ³n distribuida (Spark si necesario)

**Estimado:** Refactor de 20-30% del cÃ³digo.

### P25: Â¿CÃ³mo implementarÃ­an Machine Learning?

**R:** MÃ³dulo adicional, sin tocar pipeline:

```
Pipeline ETL
    â†“
Datos Limpios
    â”œâ†’ Dashboard (actual)
    â””â†’ ML Module (nuevo)
         â”œâ”€ Clustering de bancos
         â”œâ”€ PredicciÃ³n de morosidad
         â”œâ”€ Anomaly detection
         â””â”€ Recomendaciones
```

**TecnologÃ­a:** scikit-learn, XGBoost, Pandas

---

## ğŸ¤” PREGUNTAS SOBRE DECISIONES ESPECÃFICAS

### P26: Â¿Por quÃ© `skiprows=7` al leer el Excel?

**R:** Las primeras 7 filas son metadatos:

```
Fila 1: "SUPERINTENDENCIA DE BANCOS"
Fila 2: PerÃ­odo
Fila 3: En blanco
...
Fila 7: TÃ­tulo de columnas
Fila 8: â† Primer dato
```

`skiprows=7` = "Ignora 7 primeras, usa fila 8 como headers"

### P27: Â¿Por quÃ© melt en lugar de pivottable?

**R:** DirecciÃ³n opuesta:

- **pivot_table:** Agrupa datos (reduce filas)
- **melt:** Separa datos (aumenta filas)

Nuestro caso:
```
ENTRADA: Wide (columnas = bancos)
SALIDA:  Long (filas = observaciones)
```

`melt` es la herramienta correcta.

### P28: Â¿Por quÃ© `errors="ignore"` en drop?

**R:** Robustez ante variaciones:

```python
X.drop("BANCOS PRIVADOS VIVIENDA", axis=1, errors="ignore")
```

Si esta columna no existe en alguna hoja, no falla - continÃºa.

**Alternativa (frÃ¡gil):**
```python
X.drop("BANCOS PRIVADOS VIVIENDA", axis=1)  # Falla si no existe
```

### P29: Â¿CÃ³mo decidieron quÃ© visualizaciones incluir?

**R:** Siguiendo principios de exploraciÃ³n de datos:

**Necesitan responder:**
1. "Â¿CÃ³mo estÃ¡ este banco?" â†’ Perfil (barras)
2. "Â¿CÃ³mo se comparan?" â†’ Ranking (barras)
3. "Â¿QuiÃ©nes lideran?" â†’ Top 3 (medallas)
4. "Â¿VisiÃ³n completa?" â†’ Tabla (matrix)
5. "Â¿Hay patrones?" â†’ Heatmap
6. "Â¿EstadÃ­sticas?" â†’ MÃ©tricas

Cada visualizaciÃ³n responde una pregunta de negocio diferente.

### P30: Â¿Por quÃ© 3 categorÃ­as y no mÃ¡s?

**R:** LÃ­mite natural de los datos:

1. **Balance:** Cuentas de activos (7 indicadores naturales)
2. **Compos Carteras:** Estructura financiera (5 indicadores)
3. **Indicadores:** Ratios de rendimiento (6 indicadores)

Estos 3 vienen del excel fuente. Agregar mÃ¡s requerirÃ­a mÃ¡s datos de entrada.
## ğŸ¯ PREGUNTAS TRAMPA (Prepararse)

### P41: "Â¿No es esto muy simple?"
**R:** "Simple estÃ¡ donde se ve, pero compleja es la arquitectura. La simplicidad es resultado de buen diseÃ±o, no falta de pensamiento. Cualquiera puede escribir cÃ³digo complejo; lo difÃ­cil es hacerlo simple."

### P42: "Â¿Por quÃ© no lo hicieron en [otra tecnologÃ­a]?"
**R:** "[Otra tecnologÃ­a] tambiÃ©n funcionarÃ­a, pero Python es el estÃ¡ndar en Data Science por X razones. Cada tecnologÃ­a tiene tradeoffs; Python optimiza para esto."

### P43: "Â¿CuÃ¡l es la precisiÃ³n de los datos?"
**R:** "Los datos vienen de la Superintendencia de Bancos - 100% oficiales. Nuestro pipeline no modifica valores, solo reorganiza. PrecisiÃ³n = 100%"

### P44: "Â¿QuÃ© privacidad de datos tienen?"
**R:** "Los datos son pÃºblicos (reporte oficial). El sistema actual no encripta, pero para producciÃ³n: HTTPS + autenticaciÃ³n + base de datos encriptada."

### P45: "Â¿QuÃ© pasa si se caÃ­da el servidor?"
**R:** "Buena pregunta. Para producciÃ³n: backup automÃ¡tico, replicaciÃ³n de datos, SLA 99.9% uptime. Actualmente local, sin requerimiento de uptime."

---

## ğŸ“š RESPUESTA GENERAL PARA PREGUNTAS INESPERADAS

Si no saben la respuesta:

**"Esa es una excelente pregunta. [Sinceramente: desconocemos / No lo habÃ­amos considerado]. 

Pero [volvemos a los principios fundamentales]:
- El diseÃ±o es modular, asÃ­ que agregar eso serÃ­a [X]
- O podrÃ­amos investigarlo como mejora futura

---

## âœ… CHECKLIST FINAL

Antes de la defensa, practica responder:

- [ ] 5 preguntas sobre arquitectura
- [ ] 5 preguntas tÃ©cnicas
- [ ] 5 preguntas sobre datos
- [ ] 5 preguntas sobre dashboard
- [ ] 5 preguntas sobre productizaciÃ³n
- [ ] Practica la demo en vivo 3+ veces
- [ ] Conoce las mÃ©tricas del proyecto (lÃ­neas, clases, KPIs)
- [ ] Prepara respuestas a preguntas trampa
- [ ] Practica mantener la calma ante crÃ­tica

**Â¡Ã‰XITO EN LA DEFENSA! ğŸš€**
