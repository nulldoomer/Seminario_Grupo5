# ğŸ“Š ANÃLISIS INTEGRAL DEL PROYECTO
## Sistema de Inteligencia de Negocios para el Sistema Bancario Ecuatoriano

**Grupo:** Grupo 5 - Seminario  
**Integrantes:** Paulo YÃ©pez, Joel Acosta, Luis CaÃ±ar  
**PerÃ­odo:** 2025  
**Fecha de AnÃ¡lisis:** Noviembre 2025

---

## ğŸ“‹ RESUMEN EJECUTIVO

El proyecto **"AnÃ¡lisis Comparativo del Sistema Bancario Ecuatoriano"** es un sistema completo de inteligencia de negocios (BI) que automatiza la ingestiÃ³n, limpieza, procesamiento y visualizaciÃ³n de indicadores financieros (KPIs) de bancos ecuatorianos. 

**Valor Central:** Permite comparaciÃ³n y ranking automÃ¡tico de la salud financiera de instituciones bancarias mediante un dashboard interactivo integrado con una API REST.

---

## ğŸ¯ OBJETIVOS DEL PROYECTO

### Objetivo General
Desarrollar un sistema de inteligencia de negocios que limpie, ingiera y consolide indicadores financieros (KPIs) a travÃ©s de un dashboard interactivo para comparar y rankear los bancos del Ecuador.

### Objetivos EspecÃ­ficos
1. **Pipeline de Datos:** Desarrollar un pipeline de ETL (Extract, Transform, Load) para limpieza y tratamiento de datos desde archivos Excel
2. **TransformaciÃ³n:** Convertir datos complejos en informaciÃ³n representativa para toma de decisiones
3. **API REST:** Crear una API con FastAPI para acceso programÃ¡tico a los KPIs
4. **VisualizaciÃ³n:** Implementar un dashboard interactivo para anÃ¡lisis y comparaciÃ³n de bancos

---

## ğŸ—ï¸ ARQUITECTURA DEL SISTEMA

### 1. ESTRUCTURA GENERAL DEL PROYECTO

```
Seminario_Grupo5/
â”œâ”€â”€ api/                          # Servicio API REST
â”œâ”€â”€ scripts/                       # LÃ³gica de procesamiento
â”‚   â”œâ”€â”€ pipeline/                # ETL Pipeline
â”‚   â””â”€â”€ visualizations/          # Dashboard e interfaz
â”œâ”€â”€ dataset/                      # Datos fuente (Excel)
â”œâ”€â”€ output/                       # Datos procesados (CSV)
â””â”€â”€ doc/                          # DocumentaciÃ³n
```

### 2. COMPONENTES PRINCIPALES

#### **A. Pipeline de Datos (ETL)**

**Responsabilidad:** Transformar datos brutos en informaciÃ³n limpia y estructurada

**Flujo de Procesamiento:**

```
dataset.xlsx
    â†“
[DataIngester] â†’ Localiza el archivo fuente
    â†“
[CreateDataframes] â†’ Lee 3 hojas: BALANCE, COMPOS CART, INDICADORES
    â†“
[CleaningPipeline] â†’ Pipeline de limpieza general
    â”œâ”€â”€ DropBlankColumns: Elimina columnas vacÃ­as
    â”œâ”€â”€ DropRowsWithoutValues: Elimina filas sin datos de bancos
    â””â”€â”€ MeltBanksIndicatorsAndValues: Convierte formato WIDE â†’ LONG (TIDY)
    â†“
[BalanceCleaningPipeline] â†’ Pipeline especÃ­fico para Balance
    â””â”€â”€ TakePriorRows: Mantiene solo cÃ³digos < 100 (datos significativos)
    â†“
[MatchColumnsPipeline] â†’ Homogeniza estructura
    â”œâ”€â”€ DropCodeColumn: Elimina columna CÃ“DIGO
    â””â”€â”€ RenameColumns: Renombra CUENTA â†’ NOMBRE DEL INDICADOR
    â†“
[ConcatDataframesPipeline] â†’ Consolida 3 dataframes en uno
    â†“
[SaveCleanData] â†’ Exporta CSV final
    â†“
output/cleaned_data/Final Dataframe.csv
```

**Patrones de DiseÃ±o Utilizados:**

- **OOP (ProgramaciÃ³n Orientada a Objetos):** Cada etapa es una clase reutilizable
- **Herencia:** `BalanceCleaningPipeline` hereda de `CleaningPipeline`
- **Sklearn Pipeline Pattern:** Usa `sklearn.pipeline.Pipeline` con transformers
- **Transformers Reutilizables:** Cada componente implementa `fit()` y `transform()`

**Clases Principales:**

| Clase | Responsabilidad |
|-------|-----------------|
| `DataIngester` | Localiza y valida archivo Excel fuente |
| `CreateDataframes` | Lee mÃºltiples hojas del Excel (skiprows=7) |
| `DropBlankColumns` | Limpia columnas vacÃ­as/duplicadas |
| `DropRowsWithoutValues` | Elimina filas sin datos bancarios (thresh=3) |
| `TakePriorRows` | Filtra filas relevantes por cÃ³digo |
| `MeltBanksIndicatorsAndValues` | Pivotea datos de formato WIDE a LONG |
| `RenameColumns` | Estandariza nombres de columnas |
| `SaveCleanData` | Exporta datos limpios a CSV |

---

#### **B. Dashboard de VisualizaciÃ³n (Streamlit)**

**Responsabilidad:** Proporcionar interfaz interactiva para anÃ¡lisis de KPIs

**CaracterÃ­sticas Principales:**

1. **Arquitectura Modular:**
   - `data_loader.py`: Carga datos limpios desde CSV
   - `components/`: MÃ³dulos independientes reutilizables
   
2. **MÃ³dulos de Componentes:**

| MÃ³dulo | FunciÃ³n |
|--------|---------|
| `indicator_config.py` | Define 18 KPIs por categorÃ­a (Balance, Rendimiento, Estructura) |
| `data_handler.py` | Filtrado, agregaciÃ³n y transformaciÃ³n de datos |
| `metrics_calculator.py` | CÃ¡lculos estadÃ­sticos (promedio, mediana, desviaciÃ³n, rango) |
| `charts_builder.py` | Generador de grÃ¡ficos (barras, ranking, heatmap) |
| `ui_components.py` | Componentes UI reutilizables (tarjetas, medalles, botones) |

3. **Funcionalidades del Dashboard:**

**Panel de Control Interactivo:**
- Selector de categorÃ­a (Balance, Rendimiento, Estructura)
- Filtro de banco especÃ­fico
- Selector de indicador para ranking
- Indicadores en tiempo real del dataset

**Visualizaciones:**

| VisualizaciÃ³n | Tipo | PropÃ³sito |
|---------------|------|----------|
| Perfil Financiero | GrÃ¡fico de barras horizontal | Mostrar indicadores del banco seleccionado |
| Ranking | GrÃ¡fico de barras vertical | Comparar bancos en indicador especÃ­fico |
| Top 3 / Bottom 3 | Medallas + lista | Destacar mejor/peor desempeÃ±o |
| Tabla Comparativa | Tabla pivote | ComparaciÃ³n matricial de todos los indicadores |
| Heatmap | Mapa de calor | Identificar patrones de desempeÃ±o |
| EstadÃ­sticas Detalladas | MÃ©tricas | Media, mediana, desviaciÃ³n, rango |

**Capacidades Interactivas:**
- Filtrado dinÃ¡mico por categorÃ­a, banco e indicador
- Descarga de datos en CSV
- AnÃ¡lisis multi-banco personalizado
- EstadÃ­sticas en tiempo real
- Comparativas visuales con gradientes de color

---

#### **C. API REST (FastAPI)**

**Estado Actual:** Estructura base lista  
**Responsabilidad:** Proporcionar endpoints programÃ¡ticos para acceso a KPIs

**Ventajas de FastAPI:**
- ValidaciÃ³n automÃ¡tica de datos
- DocumentaciÃ³n interactiva (Swagger/ReDoc)
- Alto rendimiento
- Tipado estÃ¡tico

---

## ğŸ“Š ANÃLISIS DE DATOS

### Fuente de Datos
- **Origen:** Dataset de instituciones bancarias ecuatorianas
- **Formato:** Archivo Excel (.xlsx) con mÃºltiples hojas
- **PerÃ­odo:** Septiembre 2025

### Hojas del Excel Procesadas

| Hoja | Indicadores | DescripciÃ³n |
|------|-------------|-------------|
| **BALANCE** | 7 indicadores | Activos y recursos del banco (fondos, inversiones, cartera, etc.) |
| **COMPOS CART** | 5 indicadores | Estructura y composiciÃ³n del patrimonio |
| **INDICADORES** | 6 indicadores | Rendimiento y eficiencia operativa (ROA, ROE, morosidad, etc.) |

### KPIs Identificados (18 Total)

**Balance (Valores en $):**
- Fondos Disponibles, Inversiones, Cartera de CrÃ©ditos
- Deudores por Aceptaciones, Cuentas por Cobrar
- Propiedades y Equipo, Otros Activos

**Rendimiento (Porcentajes):**
- ROA: Resultados del Ejercicio / Activo Promedio
- ROE: Resultados del Ejercicio / Patrimonio Promedio
- Morosidad de la Cartera Total
- Activos Productivos / Total Activos
- Fondos Disponibles / DepÃ³sitos a Corto Plazo
- Gastos de OperaciÃ³n / Total Activo Promedio

**Estructura (Valores en $):**
- Total Activo, Total Patrimonio, Total Pasivos
- Obligaciones con el PÃºblico, Capital Social

---

## ğŸ”§ STACK TECNOLÃ“GICO

### Lenguaje de ProgramaciÃ³n
- **Python 3.10+**

### LibrerÃ­as Principales

| LibrerÃ­a | VersiÃ³n | PropÃ³sito |
|----------|---------|----------|
| `pandas` | 2.3.3+ | ManipulaciÃ³n y transformaciÃ³n de datos |
| `openpyxl` | 3.1.5+ | Lectura de archivos Excel |
| `scikit-learn` | 1.7.2+ | Pipeline de transformaciÃ³n de datos |
| `plotly` | 6.3.1+ | VisualizaciÃ³n interactiva |
| `streamlit` | 1.50.0+ | Framework para dashboard web |
| `fastapi` | (configurado) | Framework API REST |
| `missingno` | 0.5.2+ | AnÃ¡lisis de datos faltantes |

### Gestor de Proyectos
- **uv**: Gestor de dependencias y entornos virtuales
  - Automatiza creaciÃ³n de entornos virtuales
  - Gestiona dependencias de forma determinista
  - Evita conflictos de paquetes

---

## âœ… FORTALEZAS DEL PROYECTO

### 1. **Arquitectura Limpia y Modular**
- SeparaciÃ³n de responsabilidades (ETL, VisualizaciÃ³n, API)
- Componentes reutilizables y testables
- FÃ¡cil de mantener y extender

### 2. **Patrones de DiseÃ±o Avanzados**
- OOP aplicada correctamente
- Herencia para reutilizaciÃ³n de cÃ³digo
- Sklearn Pipeline Pattern para transformaciones

### 3. **AutomatizaciÃ³n Completa**
- Pipeline ETL completamente automÃ¡tico
- No requiere intervenciÃ³n manual
- Reutilizable para nuevos perÃ­odos

### 4. **VisualizaciÃ³n Profesional**
- Dashboard interactivo y responsivo
- MÃºltiples perspectivas de anÃ¡lisis
- Componentes UI reutilizables

### 5. **Escalabilidad**
- Arquitectura preparada para nuevas fuentes de datos
- FÃ¡cil agregar nuevos indicadores
- Componentes independientes

### 6. **DocumentaciÃ³n del CÃ³digo**
- Comentarios explicativos en transformers
- Docstrings en componentes
- Claridad en intenciÃ³n de cada etapa

### 7. **GestiÃ³n de Dependencias**
- Uso de `uv` simplifica setup y reproducibilidad
- `pyproject.toml` centraliza configuraciÃ³n

---

## âš ï¸ ÃREAS DE MEJORA

### 1. **Testing y ValidaciÃ³n**
- No hay tests unitarios implementados
- Falta validaciÃ³n de datos en el API
- Sin pruebas de integraciÃ³n

**Recomendaciones:**
```python
# pytest para tests unitarios
# ValidaciÃ³n con pydantic en FastAPI
# Tests de integraciÃ³n para pipeline completo
```

### 2. **API REST**
- Estructura base no completada
- Falta definir endpoints
- Sin autenticaciÃ³n

**PrÃ³ximos pasos:**
```python
@app.get("/kpis/{bank_id}")
@app.get("/ranking/{indicator}")
@app.post("/compare-banks")
```

### 3. **DocumentaciÃ³n**
- README parcialmente completo
- Falta documentaciÃ³n de API
- Sin ejemplos de uso

### 4. **Manejo de Errores**
- Pipeline con try-except genÃ©rico
- Falta logging detallado
- Sin alertas para anomalÃ­as

**Mejora:**
```python
import logging
logger = logging.getLogger(__name__)
```

### 5. **Performance**
- Sin cachÃ© en el dashboard
- Posibles cuellos de botella en grandes datasets

**SoluciÃ³n:**
```python
@st.cache_resource
def load_data():
    # Carga datos una sola vez
```

### 6. **ValidaciÃ³n de Calidad de Datos**
- Falta validaciÃ³n post-limpieza
- Sin checksums o validaciones de integridad

---

## ğŸ“ˆ FLUJO DE EJECUCIÃ“N COMPLETO

```
1. Usuario ejecuta: uv run scripts/pipeline/main.py
   â†“
2. Pipeline ETL
   - Ingesta de datos desde dataset/dataset.xlsx
   - Lectura de 3 hojas (BALANCE, COMPOS CART, INDICADORES)
   - Limpieza y transformaciÃ³n
   - ConsolidaciÃ³n en un dataframe Ãºnico
   - ExportaciÃ³n a output/cleaned_data/Final Dataframe.csv
   â†“
3. Usuario ejecuta: streamlit run scripts/visualizations/main.py
   â†“
4. Dashboard Interactivo (http://localhost:8501)
   - Carga datos limpios
   - Presenta interfaz interactiva
   - Permite anÃ¡lisis exploratorio
   - GeneraciÃ³n de reportes descargables
   â†“
5. API REST (Futuro)
   - Endpoints para consultas programÃ¡ticas
   - IntegraciÃ³n con sistemas externos
```

---

## ğŸ“ CONCEPTOS CLAVE APLICADOS

### 1. **ETL (Extract, Transform, Load)**
- **Extract:** DataIngester, CreateDataframes
- **Transform:** CleaningPipeline, BalanceCleaningPipeline, MatchColumnsPipeline
- **Load:** SaveCleanData

### 2. **TransformaciÃ³n de Datos**
- **Wide to Long:** Uso de `pd.melt()` para formato tidy
- **Limpieza:** EliminaciÃ³n de valores nulos, columnas vacÃ­as
- **EstandarizaciÃ³n:** NormalizaciÃ³n de nombres y tipos

### 3. **ProgramaciÃ³n Orientada a Objetos**
- EncapsulaciÃ³n de responsabilidades
- Herencia para reutilizaciÃ³n
- Polimorfismo en transformers

### 4. **Sklearn Pipeline Pattern**
- ComposiciÃ³n de transformadores
- Fit-transform pattern
- Reusabilidad en nuevos datos

### 5. **VisualizaciÃ³n de Datos**
- ComparaciÃ³n: GrÃ¡ficos de barras
- Ranking: Ordenamiento y posicionamiento
- DistribuciÃ³n: Heatmaps
- Tendencias: Tablas pivote

---

## ğŸ“Š MÃ‰TRICAS Y ESTADÃSTICAS

### Dimensiones del Dataset
- **Bancos Analizados:** ~10-15 instituciones
- **Indicadores por CategorÃ­a:**
  - Balance: 7 KPIs
  - Rendimiento: 6 KPIs
  - Estructura: 5 KPIs
- **Total de Puntos de Datos:** Miles de registros procesados

### EstadÃ­sticas Disponibles en Dashboard
- Media y mediana
- DesviaciÃ³n estÃ¡ndar
- MÃ­nimo y mÃ¡ximo
- Rango
- Coeficiente de variaciÃ³n

---

## ğŸš€ POSIBILIDADES DE EXPANSIÃ“N

### Corto Plazo (1-2 meses)
1. Completar API REST con endpoints CRUD
2. Implementar tests unitarios e integraciÃ³n
3. Agregar autenticaciÃ³n al API
4. DocumentaciÃ³n API (Swagger)

### Mediano Plazo (3-6 meses)
1. Base de datos relacional (PostgreSQL)
2. AutomatizaciÃ³n con cron jobs
3. Alertas automÃ¡ticas de cambios
4. PredicciÃ³n de tendencias (ML)

### Largo Plazo (6-12 meses)
1. Machine Learning para clustering de bancos
2. AnÃ¡lisis de series temporales
3. IntegraciÃ³n con fuentes de datos externas
4. AplicaciÃ³n mÃ³vil

---

## ğŸ’¡ RECOMENDACIONES PARA LA DEFENSA

### Puntos Clave a Destacar

1. **Problema Resuelto:**
   - Sistema bancario ecuatoriano requiere anÃ¡lisis centralizado
   - Proceso manual es tedioso y propenso a errores
   - SoluciÃ³n: automatizaciÃ³n completa del pipeline

2. **InnovaciÃ³n TÃ©cnica:**
   - Arquitectura escalable y modular
   - Patrones de diseÃ±o avanzados (OOP, Pipeline)
   - Dashboard interactivo profesional

3. **Valor del Negocio:**
   - Toma de decisiones basada en datos
   - ComparaciÃ³n rÃ¡pida entre instituciones
   - IdentificaciÃ³n de tendencias

4. **Impacto:**
   - ReducciÃ³n de tiempo de anÃ¡lisis (de horas a minutos)
   - PrecisiÃ³n en datos
   - Reutilizable para otros perÃ­odos

### DemostraciÃ³n en Vivo

```bash
# 1. Ejecutar pipeline
uv run scripts/pipeline/main.py

# 2. Lanzar dashboard
streamlit run scripts/visualizations/main.py

# 3. Demostrar funcionalidades:
#    - Filtrado por categorÃ­a
#    - VisualizaciÃ³n de rankings
#    - Descarga de reportes
#    - EstadÃ­sticas detalladas
```

---

## ğŸ“ CONCLUSIÃ“N

El proyecto **"AnÃ¡lisis Comparativo del Sistema Bancario Ecuatoriano"** es una soluciÃ³n integral de Business Intelligence que demuestra:

âœ… **Excelencia TÃ©cnica:** Arquitectura limpia, patrones avanzados, buenas prÃ¡cticas  
âœ… **Completitud:** Pipeline ETL + VisualizaciÃ³n + API (estructura)  
âœ… **Escalabilidad:** DiseÃ±o modular permite expansiÃ³n futura  
âœ… **Valor Real:** Automatiza anÃ¡lisis complejo de indicadores financieros  
âœ… **Profesionalismo:** Dashboard pulido y funcional  

**Siguiente Fase:** Completar API REST y agregar testing para producciÃ³n.

---

## ğŸ“š APÃ‰NDICE: ARCHIVOS DEL PROYECTO

```
scripts/pipeline/
â”œâ”€â”€ main.py                 # Orquestador principal del ETL
â”œâ”€â”€ data_ingest.py          # Ingesta de datos (DataIngester)
â”œâ”€â”€ data_processing.py      # Transformadores (7 clases)
â”œâ”€â”€ data_pipeline.py        # Pipelines (4 clases)
â””â”€â”€ data_saving.py          # Guardado de datos (SaveCleanData)

scripts/visualizations/
â”œâ”€â”€ main.py                 # Dashboard principal (Streamlit)
â”œâ”€â”€ data_loader.py          # Cargador de datos limpios
â””â”€â”€ components/
    â”œâ”€â”€ indicator_config.py     # ConfiguraciÃ³n de 18 KPIs
    â”œâ”€â”€ data_handler.py         # Manejo y filtrado de datos
    â”œâ”€â”€ metrics_calculator.py    # CÃ¡lculos estadÃ­sticos
    â”œâ”€â”€ charts_builder.py        # Generador de grÃ¡ficos
    â””â”€â”€ ui_components.py        # Componentes UI reutilizables

api/
â””â”€â”€ main.py                 # Esqueleto API FastAPI

output/cleaned_data/
â””â”€â”€ Final Dataframe.csv     # Datos procesados finales
```

---

*AnÃ¡lisis generado para propÃ³sitos de defensa acadÃ©mica*  
*Grupo 5 - Seminario Integrador - Noviembre 2025*
